# sohu_crawled
m.sohu.com爬虫

sohu.py为爬虫执行文件

crontab为定时模块的使用

（注意如果用定时模块启动默认是在后台运行）

<h3>要求</h3>

请设计一个系统，自动完成对于手机搜狐(http://m.sohu.com/ )系统可靠性的检测。具体要求：

1. 定时递归检测所有m.sohu.com域名的页面以及这些页面上的链接的可达性，即有没有出现不可访问情况。

2. m.sohu.com域名页面很多，从各个方面考虑性能优化。

3. 对于错误的链接记录到日志中，日志包括：连接，时间，错误状态等。

4. 考虑多线程的方式实现。

<h3>思路</h3>

分3个步骤实现

1.递归检测域名的所有链接，并将错误链接记录。

2.性能优化。

3.多线程和定时功能的实现。

基本上前两条是在一起实现的，观察m.sohu.com页面源代码，多数是http开头的长链接以及/开头的短链接。将短链接补全并整合再次递归。递归要注意的是：非m.sohu.com域名下的页面只进行一级检测，即不再次进行链接页面的提取及检测，以免爬出外链。优化：除了过滤不必检测的链接和javascript之外，要注意链接的重复性，主页的多个频道以及回到主页等都只需检测一次即可。

<h3>疑问</h3>

1.检测时总会卡住不动，直接Python运行到500左右时可能会卡住，用Eclipse最检测到了7000+

2.优化：添加一个失败后自动重试的功能。

3.终端显示时会有些混乱，是因为多线程的问题导致。

<h3>总结</h3>

虽然做出来了，但是并不是自己全部手打出来的，很多知识都没听说过，都是靠一点点的搜索得来，缺乏一定的创造力，此外自己的思路还是不那么的正确，还要多加练习。要学的东西还有很多，抓紧了。

<h3>下半个月：</h3>

1.看更深入一些的书《Python核心编程》《Python cook book》等。

2.多做一些Python的练习。

3.继续Django框架的学习以及MySQL的入门。
